{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from collections import Counter\n",
    "import random\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "import warnings\n",
    "warnings.filterwarnings(\"default\", \"\", DeprecationWarning, \"\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=10):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[\"label\"].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['label'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"n_estimators: %d\" % cvresult.shape[0]\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['label'].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['label'], dtrain_predprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame.from_csv(\"../data/features/block_0_10000\")\n",
    "labels = pd.DataFrame.from_csv(\"../data/train.txt\", sep='\\t')\n",
    "test = pd.DataFrame.from_csv(\"../data/features/block_0_20000\")\n",
    "labels_test = pd.DataFrame.from_csv(\"../data/train.txt\", sep='\\t')\n",
    "evals = pd.DataFrame.from_csv(\"../data/features/block_0_30000\")\n",
    "labels_test = pd.DataFrame.from_csv(\"../data/train.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"label\"] = labels[\"human-generated\"]\n",
    "test[\"label\"] = labels_test[\"human-generated\"]\n",
    "evals[\"label\"] = labels[\"human-generated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_column = train[\"label\"]\n",
    "label_column_test = test[\"label\"]\n",
    "label_column_eval = evals[\"label\"]\n",
    "features = train.drop([\"label\"], axis=1)\n",
    "features_test = test.drop([\"label\"], axis=1)\n",
    "features_eval = evals.drop([\"label\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(features.values, label_column.values, feature_names=features.columns)\n",
    "deval = xgb.DMatrix(features_eval.values, label_column_eval.values, feature_names=features_eval.columns)\n",
    "dtest = xgb.DMatrix(features_test.values, feature_names=features_test.columns)\n",
    "\n",
    "# dtrain = xgb.DMatrix(features_test.values, label_column_test.values, feature_names=features_test.columns)\n",
    "# dtest = xgb.DMatrix(features.values, feature_names=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'eta':0.1, 'max_depth':5, 'min_child_weight':1, 'gamma':0.1,\n",
    "         'silent':0, 'subsample':0.8, 'colsample_bytree': 0.8,  \n",
    "         'objective':'binary:logistic', 'eval_metric':'auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.675731594868\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(param, dtrain, num_boost_round=16)\n",
    "preds = bst.predict(dtest)\n",
    "print roc_auc_score(label_column_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.634107</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.685703</td>\n",
       "      <td>0.004771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.651291</td>\n",
       "      <td>0.010905</td>\n",
       "      <td>0.710904</td>\n",
       "      <td>0.002220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.656231</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.723176</td>\n",
       "      <td>0.001878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.663925</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.733925</td>\n",
       "      <td>0.004162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.664821</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.743344</td>\n",
       "      <td>0.005925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.663885</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.751952</td>\n",
       "      <td>0.006136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.663475</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.759131</td>\n",
       "      <td>0.005349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.663857</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.764271</td>\n",
       "      <td>0.005933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.664329</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.770650</td>\n",
       "      <td>0.006131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.664867</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.778056</td>\n",
       "      <td>0.005915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
       "0       0.634107      0.008499        0.685703       0.004771\n",
       "1       0.651291      0.010905        0.710904       0.002220\n",
       "2       0.656231      0.005924        0.723176       0.001878\n",
       "3       0.663925      0.004143        0.733925       0.004162\n",
       "4       0.664821      0.001064        0.743344       0.005925\n",
       "5       0.663885      0.000550        0.751952       0.006136\n",
       "6       0.663475      0.001395        0.759131       0.005349\n",
       "7       0.663857      0.002058        0.764271       0.005933\n",
       "8       0.664329      0.002051        0.770650       0.006131\n",
       "9       0.664867      0.004934        0.778056       0.005915"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.cv(param, dtrain, metrics=(\"auc\"), shuffle=True, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tev1-auc:0.635119\n",
      "Will train until ev1-auc hasn't improved in 5 rounds.\n",
      "[1]\tev1-auc:0.663674\n",
      "[2]\tev1-auc:0.671708\n",
      "[3]\tev1-auc:0.672349\n",
      "[4]\tev1-auc:0.673063\n",
      "[5]\tev1-auc:0.673889\n",
      "[6]\tev1-auc:0.674935\n",
      "[7]\tev1-auc:0.674331\n",
      "[8]\tev1-auc:0.675056\n",
      "[9]\tev1-auc:0.674902\n",
      "[10]\tev1-auc:0.67559\n",
      "[11]\tev1-auc:0.67474\n",
      "[12]\tev1-auc:0.674801\n",
      "[13]\tev1-auc:0.675025\n",
      "[14]\tev1-auc:0.67536\n",
      "[15]\tev1-auc:0.676632\n",
      "[16]\tev1-auc:0.677555\n",
      "[17]\tev1-auc:0.678774\n",
      "[18]\tev1-auc:0.678403\n",
      "[19]\tev1-auc:0.678621\n",
      "[20]\tev1-auc:0.678906\n",
      "[21]\tev1-auc:0.679342\n",
      "[22]\tev1-auc:0.678234\n",
      "[23]\tev1-auc:0.678612\n",
      "[24]\tev1-auc:0.678375\n",
      "[25]\tev1-auc:0.6778\n",
      "[26]\tev1-auc:0.678664\n",
      "Stopping. Best iteration:\n",
      "[21]\tev1-auc:0.679342\n",
      "\n",
      "0.676423765019\n"
     ]
    }
   ],
   "source": [
    "bst_early = xgb.train(param, dtrain, evals=[(deval,\"ev1\")], num_boost_round=200, early_stopping_rounds=5)\n",
    "preds = bst_early.predict(dtest)\n",
    "print roc_auc_score(label_column_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_early.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate = 0.3,\n",
    " n_estimators=30,\n",
    " max_depth=6,\n",
    " min_child_weight=2,\n",
    " gamma=0.3,\n",
    " subsample=0.9,\n",
    " colsample_bytree=0.6,\n",
    " reg_alpha=100,\n",
    " objective= 'binary:logistic',\n",
    " scale_pos_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  25 out of  25 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: 0.66857, std: 0.01114, params: {'reg_lambda': 1e-05}, mean: 0.66857, std: 0.01114, params: {'reg_lambda': 0.01}, mean: 0.66883, std: 0.01088, params: {'reg_lambda': 0.1}, mean: 0.66849, std: 0.01016, params: {'reg_lambda': 1}, mean: 0.66868, std: 0.00785, params: {'reg_lambda': 100}]\n",
      "{'reg_lambda': 0.1} 0.668828425957\n"
     ]
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'reg_lambda':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = xgb1, param_grid = param_test1, scoring='roc_auc', verbose=1, \n",
    "                        n_jobs=6,iid=False, cv=5)\n",
    "\n",
    "gsearch1.fit(train[features.columns],train[\"label\"])\n",
    "print gsearch1.grid_scores_\n",
    "print gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000 loops, best of 3: 10.4 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
